{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import urllib.request, json, re\n",
    "import pprint as pp\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "import random\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassformat för lagring och serialisering\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DocList:\n",
    "    data = []\n",
    "    def __init__(self):\n",
    "        self.name='MotionList'\n",
    "        self.data = []\n",
    "    def reprJSON(self):\n",
    "        return dict(name=self.name, data=self.data) \n",
    "    \n",
    "class Motion:\n",
    "    def __init__(self):\n",
    "        self.text=''\n",
    "        self.title=''\n",
    "        self.subtype=''\n",
    "        self.meta = {}\n",
    "    def reprJSON(self):\n",
    "        return dict(text=self.text, subtype=self.subtype, title=self.title, meta=self.meta) \n",
    "    \n",
    "class DocSerializer(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if hasattr(obj,'reprJSON'):\n",
    "            return obj.reprJSON()\n",
    "        else:\n",
    "            return json.JSONEncoder.default(self, obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import och skapande av datafil\n",
    "denna koden ska bara köras en gång vid inläsning av data från riksdagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalt antal dokument: 200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def import_web_data(datasize=3):\n",
    "\n",
    "    #http://data.riksdagen.se/dokumentlista/?doktyp=mot\n",
    "    #http://data.riksdagen.se/dokument/H502225.text (exempeldok.)\n",
    "    #\"http://data.riksdagen.se/anforandelista/?rm=&anftyp=Nej&d=&ts=&parti=s&iid=0218878014918&sz=\"+str(datasize)+\"&utformat=json\"\n",
    "    #http://data.riksdagen.se/anforandelista/?rm=&anftyp=&d=&ts=&parti=&iid=&sz=10&utformat=xml\n",
    "    motioner = DocList()\n",
    "    with urllib.request.urlopen(\"http://data.riksdagen.se/dokumentlista/?doktyp=mot&sz=\"+str(datasize)+\"&utformat=json\") as url:\n",
    "        rawdata = json.loads(url.read().decode())\n",
    "        motionslista = rawdata['dokumentlista']['dokument']\n",
    "        for meta in motionslista:\n",
    "            motion = Motion()\n",
    "            with urllib.request.urlopen('http:' + meta['dokument_url_text']) as text:\n",
    "                motion.text = re.sub('\\n','',text.read().decode())\n",
    "                #motion.meta = meta (save space appr 30%)\n",
    "                motion.title = meta['titel']\n",
    "                motion.subtype = meta['subtyp']\n",
    "            motioner.data.append(motion)\n",
    "\n",
    "     \n",
    "    toJson = json.dumps(motioner.reprJSON(), cls=DocSerializer,  sort_keys=True, indent=4)\n",
    "    with open('motioner.txt','w',encoding='utf-8') as f:\n",
    "        \n",
    "        f.write(toJson) #json.dumps(motions.reprJSON()))#json.dumps(motions, sort_keys=True, indent=4))\n",
    "        \n",
    "    return toJson, motioner\n",
    "\n",
    "#datasize är antal dokument vi behöver förmodligen ett hundratal iaf. (nedan är bortkommenterad om man har fil)\n",
    "#data_ex, motionList = import_web_data(datasize=500)\n",
    "print(\"totalt antal dokument: \" + str(len(motionList.data)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_to_json(filename):\n",
    "    with open(filename,encoding=\"utf-8\") as f:\n",
    "        data = json.loads(f.read())\n",
    "        return data\n",
    "    \n",
    "def json_to_vec(jsondata):\n",
    "    docs = []\n",
    "    words = []\n",
    "    for sample in jsondata:\n",
    "        cleaned = re.sub('[\\.|,|?|!|\\-|\"\\'|\\(|\\)|;|:]', ' ', sample[\"text\"])\n",
    "        words += cleaned.lower().split()\n",
    "        docs.append(cleaned)\n",
    "\n",
    "    #print(speech)\n",
    "    #data = tf.compat.as_str(speech).split()\n",
    "    return docs, words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  läs från fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 200 \n",
      "Words:268287\n"
     ]
    }
   ],
   "source": [
    "jsondata = file_to_json(\"motioner.txt\")\n",
    "\n",
    "docs, words = json_to_vec(jsondata['data'])\n",
    "\n",
    "print(\"Docs: {0} \\nWords:{1}\".format(len(docs),len(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  Lemmatisering av alla ord\n",
    "Här måste vi gå igenom alla ord och rensa upp för att sedan ersätta ord i texten med en mindre ordrymd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from 268287 to: 9637\n"
     ]
    }
   ],
   "source": [
    "def indexOf(text, elem):\n",
    "        try:\n",
    "            thing_index = text.index(elem)\n",
    "            return thing_index\n",
    "        except ValueError:\n",
    "            return -1\n",
    "\n",
    "        \n",
    "#skapar en dictionary över gammalt till nytt ord så man kan köra find-replace med den senare.\n",
    "def lemmatize(all_words, sensitivity=.5):        \n",
    "    # a jph production yeahh\n",
    "    # unika ord (set)\n",
    "    myset = set(all_words)\n",
    "    # till lista igen\n",
    "    all_words = list(myset)\n",
    "    #sortera bokstav\n",
    "    \n",
    "    all_words.sort(reverse=False)\n",
    "    \n",
    " \n",
    "    orig = all_words\n",
    "    newlist = []\n",
    "    w_count=0\n",
    "    regexp = re.compile('(.?[0-9]+)|^[/&%\\[=\\–]') #rensa tecken\n",
    "    for i in range(len(orig)):\n",
    "        if(regexp.match(orig[i])):\n",
    "            newlist.append('')\n",
    "        else:\n",
    "            fidx = 0\n",
    "            if(len(newlist)>0):\n",
    "                suffix=0\n",
    "                if(len(orig[i])>7):\n",
    "                    suffix = 2\n",
    "                fidx = (indexOf(orig[i],newlist[i-1][:len(orig[i])-suffix])+1)\n",
    "            #kolla om längd på aktuellt ersättningsord (newlist[i-1]) är över dellängd av nuvarande ord (eg .6 = 60%)\n",
    "            #ifall denna skillnad blir för stor byt ersättningsord\n",
    "            if(fidx != 0 and ((1.0*len(newlist[i-1])/len(orig[i]) >=sensitivity) or len(newlist[i-1]) > 4)):\n",
    "                newlist.append(newlist[i-1])\n",
    "            else:\n",
    "                w_count+=1\n",
    "                newlist.append(orig[i])\n",
    "    \n",
    "    return dict(list(zip(orig,newlist))),newlist, w_count\n",
    "\n",
    "\n",
    "wdict,newlist,w_count = lemmatize(words,sensitivity=.4)\n",
    "print(\"from \"+str(len(words))+\" to: \"+str(w_count))\n",
    "tmpwords = list(set(newlist))\n",
    "tmpwords.sort( reverse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
